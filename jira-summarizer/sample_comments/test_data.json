[{"Issue key": "ZOOKEEPER-4744", "Request type": "Bug", "Datetime creation": "2023-09-15 13:11:40", "Datetime resolution": null, "Reporter login": "JIRAUSER301410", "Reporter name": "Maria Ramos", "Assignee login": null, "Assignee name": null, "Status": "Open", "Description": "The underlying issue stems from consecutive writes to the log file that are not interleaved with {{fsync}} operations. This is a well-documented behavior of operating systems, and there are several references addressing this problem:\r\n - [https://www.usenix.org/conference/osdi14/technical-sessions/presentation/pillai]\r\n - [https://dl.acm.org/doi/pdf/10.1145/2872362.2872406]\r\n - [https://mariadb.com/kb/en/atomic-write-support/]\r\n - [https://pages.cs.wisc.edu/~remzi/OSTEP/file-journaling.pdf] (Page 9)\r\n\r\nThis issue can be replicated using [LazyFS|https://github.com/dsrhaslab/lazyfs], a file system capable of simulating power failures and exhibiting the OS behavior mentioned above, i.e., the out-of-order file writes at the disk level. LazyFS persists these writes out of order and then crashes to simulate a power failure.\r\n\r\nTo reproduce this problem, one can follow these steps:\r\n\r\n{*}1{*}. Mount LazyFS on a directory where ZooKeeper data will be saved, with a specified root directory. Assuming the data path for ZooKeeper is {{/home/data/zk}} and the root directory is {{{}/home/data/zk-root{}}}, add the following lines to the default configuration file (located in the {{config/default.toml}} directory):\r\n\r\n{{[[injection]]\u00a0}}\r\n{{type=\"reorder\"\u00a0}}\r\n{{occurrence=1\u00a0}}\r\n{{op=\"write\"\u00a0}}\r\n{{file=\"/home/data/zk-root/version-2/log.100000001\"\u00a0}}\r\n{{persist=[3]}}\r\n\r\nThese lines define a fault to be injected. A power failure will be simulated after the third write to the {{/home/data/zk-root/version-2/log.100000001}} file. The `occurrence` parameter allows specifying that this is the first group where this happens, as there might be more than one group of consecutive writes.\r\n\r\n{*}2{*}. Start LazyFS as the underlying file system of a node_ in the cluster with the following command:\r\n\r\n{{\u00a0 \u00a0 \u00a0./scripts/mount-lazyfs.sh -c config/default.toml -m /home/data/zk -r /home/data/zk-root -f}}\r\n\r\n{*}3{*}. Start ZooKeeper with the command:\r\n{{\u00a0 \u00a0 \u00a0apache-zookeeper-3.7.1-bin/bin/zkServer.sh start-foreground}}\r\n\r\n\u00a0 {*}4{*}. Connect a client to the node that has LazyFS as the underlying file system:\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 {{apache-zookeeper-3.7.1-bin/bin/zkCli.sh -server 127.0.0.1:2181}}\r\n\r\nImmediately after this step, LazyFS will be unmounted, simulating a power failure, and ZooKeeper will keep printing error messages in the terminal, requiring a forced shutdown.\r\nAt this point, one can analyze the logs produced by LazyFS to examine the system calls issued up to the moment of the fault. Here is a simplified version of the log:\r\n\r\n{'syscall': 'create', 'path': '/home/gsd/data/zk37-root/version-2/log.100000001', 'mode': 'O_TRUNC'}\r\n\r\n{'syscall': 'write', 'path': '/home/data/zk37-root/version-2/log.100000001', 'size': '16', 'off': '0'}\r\n\r\n{'syscall': 'write', 'path': '/home/data/zk37-root/version-2/log.100000001', 'size': '1', 'off': '67108879'}\r\n\r\n{'syscall': 'write', 'path': '/home/data/zk37-root/version-2/log.100000001', 'size': '67108863', 'off': '16'}\r\n\r\n{'syscall': 'write', 'path': '/home/data/zk37-root/version-2/log.100000001', 'size': '61', 'off': '16'}\r\n\r\nNote that the third write is issued by LazyFS for padding.\r\n\r\n\u00a0\r\n{*}5{*}. Remove the fault from the configuration file, unmount the file system with\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0{{fusermount -uz /home/data/zk}}\r\n\r\n{*}6{*}. Mount LazyFS again with the previously provided command.\r\n\r\n\u00a0 {*}7{*}. Attempt to start ZooKeeper (it fails).\r\n\r\nBy following these steps, one can replicate the issue and analyze the effects of the power failure on ZooKeeper's restart process.", "Comments": []}]